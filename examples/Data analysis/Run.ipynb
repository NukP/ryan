{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic data analysis and plotting.\n",
    "\n",
    "### __How to use__\n",
    "- Put the files to be analyzed in the Data folder.\n",
    "- Click Run All button. \n",
    "- The processed files will be put in the Output folder. \n",
    "- The exported graph will be placed in Graph export folder. \n",
    "\n",
    "\n",
    "### __Supported experiment type__\n",
    " - __Single experiment__\n",
    "    - With/ without LC data.\n",
    "    - With / without temperature data\n",
    "    - With / without pressure data\n",
    "    - Flow data (with automatic removing of GC injection data points, this help reducing overshooting of FE due to inconsistent flow.)\n",
    "        - Recorded with DryCal software. \n",
    "        - Recorded with the custom Python script.\n",
    "        \n",
    "- __Multiplexing from 2 units and more__\n",
    "    - With / without temperature data\n",
    "    - With / without pressure data\n",
    "    - LC data is supported at this version (provided the LC file is placed directly inside eash unit's folder)\n",
    "    - Automatic flow data slicing and removing GC valve switching and GC injection data points. The flow data has to be recorded using the custom python script. \n",
    "    - Compatible with 1 and more GC folders / flow meter files for one multiplex experiment.\n",
    "\n",
    "### __Files requirement__\n",
    "- **** The naming of the files have to be strictly follow the following convention to ensure the smooth running of the script.\n",
    "- Unless specified otherwise, no space can be used. Please use underscore (_).\n",
    "- Unless specified otherwise (LC data has different format), the date info has to be in the format of yyyymmdd. For example: 20230622.\n",
    "\n",
    "- __Single experiment__\n",
    "\n",
    "    - __Pressure data (optional):__ Two files are required.\n",
    "        - pressure file: \n",
    "            - In the format of yyyymmdd_XXX-pressure.csv \n",
    "            - Inside the file, ensure the columns name are UXLiquid(Read)[mbar] and UXGas(Read)[mbar] (X is the number of the unit)\n",
    "        - pressure log:\n",
    "            - In the format of yyyymmdd_XXX-pressurelog.txt\n",
    "    - __Temperature data (optional):__ One file is required.\n",
    "        - temperature file:\n",
    "            - In the format of yyyymmdd_XXX-temperature.csv \n",
    "            - The script will take column B as the cell temperature and column D as a room temperature. \n",
    "    - __Flow data (required):__ Two files are required. \n",
    "        - Flow file: \n",
    "            - In the format of yyyymmdd_XXX-flow.csv \n",
    "            - This can be from the custom script or from DryCal program. \n",
    "        - GC files folder:\n",
    "            - In the format of yyyymmdd_XXX-GC.zip\n",
    "            - This is used to remove the artifact points resulted from GC injection. We found that this usually lead to incorrect FE calculation. By default, the script will remove all flow data recorded within the time windows of 75 seconds before and after the GC injection.\n",
    "\n",
    "- __Multiplex experiment__\n",
    "    - Capable of analyzing  multiplex experiment from 2 cells onward.\n",
    "    - For a folder containing a multiplex experiment, the name of the folder must be started with 'Multiplex'\n",
    "    - The script will take anything between the first and second (if any) underscore as the experiment name: eg. Multiplex2_30p-flow-NoEDC, the exp name will be 30p-flow-NoEDC. Multiplex_20230805_30p-flow-NoEDC, exp name will be 20230805.\n",
    "\n",
    "    -__Flow data (required):__\n",
    "        - Must be in the format of collection-[sequence of unit]-flow.csv. For example, if the the said flow data stores the flow data from unit U2 and U4 (alternating) the naming would be collection-U2-U4-flow.csv. \n",
    "\n",
    "    -__GC data (required):__\n",
    "        - Must be in the format of collection-[sequence of unit]-GC.zip. For example, if the the said flow data stores the flow data from unit U2 and U4 (alternating) the naming would be collection-U2-U4-GC.zip \n",
    "    \n",
    "    -__Echem files (required):__ \n",
    "        - Echem files for each unit must be stored inside a unit folder (naming UX, where X is the unit number.)\n",
    "\n",
    "    -__Pressure data (optional):__ \n",
    "        - pressure file: \n",
    "            - In the format of yyyymmdd_XXX-pressure.csv \n",
    "            - Inside the file, ensure the columns name are UXLiquid(Read)[mbar] and UXGas(Read)[mbar] (X is the number of the unit). The script will slice take the pressure from the number in this file. Make sure there are columns from U1 to U8. \n",
    "        - pressure log:\n",
    "            - In the format of yyyymmdd_XXX-pressurelog.txt\n",
    "\n",
    "    -__Temperature data (optional):__ One file is required.\n",
    "        - temperature file:\n",
    "            - In the format of yyyymmdd_XXX-temperature.csv \n",
    "            - The temp column of each unit is in the format of Unit X Last (C). Note that here the space is used. The room temperature is in the column called RT-external Last (C). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from ryan.analyzer import autoanalyze as aa\n",
    "from ryan.analyzer import autoplot as ap\n",
    "from ryan.analyzer import auxiliary as aux"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data slicing\n",
    "- Clean 'Recipe/data_for_dgbowl' for any old data and prepare for the current data.\n",
    "- Slice data and prepare them for processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.clear_dir('Recipe/data_for_dgbowl')\n",
    "aux.data_slicer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yadg and dgpost\n",
    "- ### Multiprocessing\n",
    "    - __False:__\n",
    "        - The script will process the data folder by folder using only one CPU core. This method can be slower in many cases but will ensure that the sure can use a computer while running the script. \n",
    "    - __True:__\n",
    "        - The script will use ALL of the CPU cores avilable in the machine to process the data. Each core will responsible for one folder. \n",
    "        - This can greatly reduce the time required for processing the data, and the processing time will be greatly be affected by the computational power of the machine. \n",
    "        - WARNING!! Using this feature can make the machine become lag to the point where other task cannot be run and cause programs to crash. It is highly adviced to leave the machine running the script and not working on other programs. In case of large files (especially for multiplex8 experiment), the system can run out of memory (RAM), resulting in a slow down of the system. In such case, single core processing is adviced (Multiprocessing=False). \n",
    "\n",
    "- ### Mannual recipe\n",
    "    - This feature allows the user to choose whether they will manually create the recipe for yadg and dgpost themselves or will let the system to dynamically create the recipes based on the data avilability and the experiment being run. \n",
    "    - __manual_recipe=True__: The user will create a custom recipe for yadg/dgpost and put the recipes in Recipe/yadg and Recipe/dgpost\n",
    "    - __manual_recipe=False__: The user will let the system to dynamically generate the recipe for yadg / dgpost.\n",
    "        - Currently,only the dgpost recipe will be adjusted. Here are the following points that the script will look into and adjust the recipe accordingly:\n",
    "            - __Temperature__:\n",
    "                - If there is a temperature file, the recipe will read the temp. data\n",
    "                - If there is no temperature file, the recipe will put the default of 20 Celcius. \n",
    "            - __Pressure__:\n",
    "                - The recipe will extract the pressure file only if there is a pressure files. \n",
    "            - __pH__:\n",
    "                - The recipe will extract the pH from the metadata file.\n",
    "            - __LC data__:\n",
    "                - The script will generate the recipe for LC files, only if there is LC data. \n",
    "            - __Correctly assgined the charge to C for each experiment__:\n",
    "                - The charge for C wil be assigned to 4 for CO<sub>2</sub>RR and 2 for CORR for the caluclation of FE for GC. \n",
    "                - The information on the reaction being performed will be extracted from the metadata file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\") #Suppress UserWarning from openpyxl library\n",
    "aa.auto_dgbowl(multi_processing=False, show_log=False, manual_recipe=False, clean_temp_dir=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\") #Suppress UserWarning from openpyxl library\n",
    "ap.dir_make_graph(type='GC', format='png', save_fig=False, path_output='Graph_Export')\n",
    "ap.dir_make_graph('Output',type='LC', save_fig=False, path_output='Graph_Export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ryan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
